{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=========================================================================<br>\n",
    "  (c) Copyright 2020<br>\n",
    "  All rights reserved<br>\n",
    "  Programs written by Hao Liu<br>\n",
    "  Department of Computer Science<br>\n",
    "  New Jersey Institute of Technology<br>\n",
    "  University Heights, Newark, NJ 07102, USA<br>\n",
    "<br>\n",
    "  Permission to use, copy, modify, and distribute this<br>\n",
    "  software and its documentation for any purpose and without<br>\n",
    "  fee is hereby granted, provided that this copyright<br>\n",
    "  notice appears in all copies. Programmer(s) makes no<br>\n",
    "  representations about the suitability of this<br>\n",
    "  software for any purpose.  It is provided \"as is\" without<br>\n",
    "  express or implied warranty.<br>\n",
    "========================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import class_weight\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras import regularizers\n",
    "import numpy as np\n",
    "import sys\n",
    "import csv\n",
    "import os\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "except Exception as e:\n",
    "    print('turn off loggins is not supported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(datafile, series_len, start_feature, n_features, mask_value, type, time_window):\n",
    "    df = pd.read_csv(datafile, header=None)\n",
    "    df_values0 = df.values\n",
    "    if type == 'gru':\n",
    "        if time_window == 12:\n",
    "            df_values = df_values0[:,\n",
    "                        [0, 1, 2, 3, 11, 13, 7, 8, 15, 18, 21, 6, 9, 10, 17, 5, 16, 4, 12, 19, 20, 14]]  # 12   GRU\n",
    "        elif time_window == 24:\n",
    "            df_values = df_values0[:,\n",
    "                        [0, 1, 2, 3, 11, 13, 15, 5, 20, 9, 21, 7, 8, 6, 17, 18, 10, 14, 4, 12, 16, 19]]  # 24   GRU\n",
    "        elif time_window == 36:\n",
    "            df_values = df_values0[:,\n",
    "                        [0, 1, 2, 3, 11, 5, 13, 20, 9, 21, 15, 8, 7, 4, 6, 14, 12, 17, 10, 18, 16, 19]]  # 36   GRU\n",
    "        elif time_window == 48:\n",
    "            df_values = df_values0[:,\n",
    "                        [0, 1, 2, 3, 11, 5, 13, 20, 9, 14, 8, 7, 21, 6, 4, 15, 12, 17, 16, 10, 18, 19]]  # 48   GRU\n",
    "        elif time_window == 60:\n",
    "            df_values = df_values0[:,\n",
    "                        [0, 1, 2, 3, 11, 5, 13, 20, 7, 15, 8, 14, 6, 21, 4, 9, 12, 10, 19, 18, 16, 17]]  # 60   GRU\n",
    "    elif type == 'lstm':\n",
    "        if time_window == 12:\n",
    "            df_values = df_values0[:,\n",
    "                        [0, 1, 2, 3, 11, 13, 20, 7, 15, 8, 21, 6, 18, 5, 10, 9, 17, 16, 19, 12, 14, 4]]  # 12   LSTM\n",
    "        elif time_window == 24:\n",
    "            df_values = df_values0[:,\n",
    "                        [0, 1, 2, 3, 20, 11, 13, 9, 15, 14, 8, 7, 5, 21, 6, 17, 18, 10, 12, 16, 4, 19]]  # 24   LSTM\n",
    "        elif time_window == 36:\n",
    "            df_values = df_values0[:,\n",
    "                        [0, 1, 2, 3, 11, 20, 13, 5, 14, 8, 15, 7, 9, 21, 6, 4, 12, 17, 18, 10, 16, 19]]  # 36   LSTM\n",
    "        elif time_window == 48:\n",
    "            df_values = df_values0[:,\n",
    "                        [0, 1, 2, 3, 11, 5, 20, 13, 9, 14, 7, 15, 8, 6, 4, 21, 12, 17, 18, 16, 10, 19]]  # 48   LSTM\n",
    "        elif time_window == 60:\n",
    "            df_values = df_values0[:,\n",
    "                        [0, 1, 2, 3, 11, 5, 13, 20, 7, 15, 8, 14, 6, 21, 4, 9, 12, 10, 19, 18, 16, 17]]  # 60   LSTM\n",
    "    X = []\n",
    "    y = []\n",
    "    tmp = []\n",
    "    for k in range(start_feature, start_feature + n_features):\n",
    "        tmp.append(mask_value)\n",
    "    n_neg = 0\n",
    "    n_pos = 0\n",
    "    for idx in range(0, len(df_values)):\n",
    "        each_series_data = []\n",
    "        row = df_values[idx]\n",
    "        label = row[0]\n",
    "        if label == 'padding':\n",
    "            continue\n",
    "        has_zero_record = False\n",
    "        # if one of the physical feature values is missing, then discard it.\n",
    "        for k in range(start_feature, start_feature + n_features):\n",
    "            if float(row[k]) == 0.0:\n",
    "                has_zero_record = True\n",
    "                break\n",
    "        if has_zero_record is False:\n",
    "            cur_harp_num = int(row[3])\n",
    "            each_series_data.append(row[start_feature:start_feature + n_features].tolist())\n",
    "            itr_idx = idx - 1\n",
    "            while itr_idx >= 0 and len(each_series_data) < series_len:\n",
    "                prev_row = df_values[itr_idx]\n",
    "                prev_harp_num = int(prev_row[3])\n",
    "                if prev_harp_num != cur_harp_num:\n",
    "                    break\n",
    "                has_zero_record_tmp = False\n",
    "                for k in range(start_feature, start_feature + n_features):\n",
    "                    if float(prev_row[k]) == 0.0:\n",
    "                        has_zero_record_tmp = True\n",
    "                        break\n",
    "                if float(prev_row[-5]) >= 3500 or float(prev_row[-4]) >= 65536 or \\\n",
    "                        abs(float(prev_row[-1]) - float(prev_row[-2])) > 70:\n",
    "                    has_zero_record_tmp = True\n",
    "                if len(each_series_data) < series_len and has_zero_record_tmp is True:\n",
    "                    each_series_data.insert(0, tmp)\n",
    "                if len(each_series_data) < series_len and has_zero_record_tmp is False:\n",
    "                    each_series_data.insert(0, prev_row[start_feature:start_feature + n_features].tolist())\n",
    "                itr_idx -= 1\n",
    "            while len(each_series_data) > 0 and len(each_series_data) < series_len:\n",
    "                each_series_data.insert(0, tmp)\n",
    "            if (label == 'N' or label == 'P') and len(each_series_data) > 0:\n",
    "                X.append(np.array(each_series_data).reshape(series_len, n_features).tolist())\n",
    "                if label == 'N':\n",
    "                    y.append(0)\n",
    "                    n_neg += 1\n",
    "                elif label == 'P':\n",
    "                    y.append(1)\n",
    "                    n_pos += 1\n",
    "    X_arr = np.array(X)\n",
    "    y_arr = np.array(y)\n",
    "    nb = n_neg + n_pos\n",
    "    return X_arr, y_arr, nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_3d_block(hidden_states, series_len):\n",
    "    hidden_size = int(hidden_states.shape[2])\n",
    "    hidden_states_t = Permute((2, 1), name='attention_input_t')(hidden_states)\n",
    "    hidden_states_t = Reshape((hidden_size, series_len), name='attention_input_reshape')(hidden_states_t)\n",
    "    score_first_part = Dense(series_len, use_bias=False, name='attention_score_vec')(hidden_states_t)\n",
    "    score_first_part_t = Permute((2, 1), name='attention_score_vec_t')(score_first_part)\n",
    "    h_t = Lambda(lambda x: x[:, :, -1], output_shape=(hidden_size, 1), name='last_hidden_state')(hidden_states_t)\n",
    "    score = dot([score_first_part_t, h_t], [2, 1], name='attention_score')\n",
    "    attention_weights = Activation('softmax', name='attention_weight')(score)\n",
    "    context_vector = dot([hidden_states_t, attention_weights], [2, 1], name='context_vector')\n",
    "    context_vector = Reshape((hidden_size,))(context_vector)\n",
    "    h_t = Reshape((hidden_size,))(h_t)\n",
    "    pre_activation = concatenate([context_vector, h_t], name='attention_output')\n",
    "    attention_vector = Dense(hidden_size, use_bias=False, activation='tanh', name='attention_vector')(pre_activation)\n",
    "    return attention_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm(n_features, series_len):\n",
    "    inputs = Input(shape=(series_len, n_features,))\n",
    "    lstm_out = LSTM(10, return_sequences=True, dropout=0.5, recurrent_dropout=0.3)(inputs)\n",
    "    attention_mul = attention_3d_block(lstm_out, series_len)\n",
    "    layer1 = Dense(100, activation='relu')(attention_mul)\n",
    "    layer1 = Dropout(0.25)(layer1)\n",
    "    output = Dense(1, activation='sigmoid', activity_regularizer=regularizers.l2(0.0001))(layer1)\n",
    "    model = Model(inputs=[inputs], outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gru(n_features, series_len):\n",
    "    inputs = Input(shape=(series_len, n_features,))\n",
    "    lstm_out = GRU(10, return_sequences=True, dropout=0.5, recurrent_dropout=0.3)(inputs)\n",
    "    attention_mul = attention_3d_block(lstm_out, series_len)\n",
    "    layer1 = Dense(100, activation='relu')(attention_mul)\n",
    "    layer1 = Dropout(0.25)(layer1)\n",
    "    output = Dense(1, activation='sigmoid', activity_regularizer=regularizers.l2(0.0001))(layer1)\n",
    "    model = Model(inputs=[inputs], outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_result(test_data_file, result_file, type, time_window, start_feature, n_features, thresh):\n",
    "    df = pd.read_csv(test_data_file, header=None)\n",
    "    df_values0 = df.values\n",
    "    if type == 'gru':\n",
    "        if time_window == 12:\n",
    "            df_values = df_values0[:,\n",
    "                        [0, 1, 2, 3, 11, 13, 7, 8, 15, 18, 21, 6, 9, 10, 17, 5, 16, 4, 12, 19, 20, 14]]  # 12   GRU\n",
    "        elif time_window == 24:\n",
    "            df_values = df_values0[:,\n",
    "                        [0, 1, 2, 3, 11, 13, 15, 5, 20, 9, 21, 7, 8, 6, 17, 18, 10, 14, 4, 12, 16, 19]]  # 24   GRU\n",
    "        elif time_window == 36:\n",
    "            df_values = df_values0[:,\n",
    "                        [0, 1, 2, 3, 11, 5, 13, 20, 9, 21, 15, 8, 7, 4, 6, 14, 12, 17, 10, 18, 16, 19]]  # 36   GRU\n",
    "        elif time_window == 48:\n",
    "            df_values = df_values0[:,\n",
    "                        [0, 1, 2, 3, 11, 5, 13, 20, 9, 14, 8, 7, 21, 6, 4, 15, 12, 17, 16, 10, 18, 19]]  # 48   GRU\n",
    "        elif time_window == 60:\n",
    "            df_values = df_values0[:,\n",
    "                        [0, 1, 2, 3, 11, 5, 13, 20, 7, 15, 8, 14, 6, 21, 4, 9, 12, 10, 19, 18, 16, 17]]  # 60   GRU\n",
    "    elif type == 'lstm':\n",
    "        if time_window == 12:\n",
    "            df_values = df_values0[:,\n",
    "                        [0, 1, 2, 3, 11, 13, 20, 7, 15, 8, 21, 6, 18, 5, 10, 9, 17, 16, 19, 12, 14, 4]]  # 12   LSTM\n",
    "        elif time_window == 24:\n",
    "            df_values = df_values0[:,\n",
    "                        [0, 1, 2, 3, 20, 11, 13, 9, 15, 14, 8, 7, 5, 21, 6, 17, 18, 10, 12, 16, 4, 19]]  # 24   LSTM\n",
    "        elif time_window == 36:\n",
    "            df_values = df_values0[:,\n",
    "                        [0, 1, 2, 3, 11, 20, 13, 5, 14, 8, 15, 7, 9, 21, 6, 4, 12, 17, 18, 10, 16, 19]]  # 36   LSTM\n",
    "        elif time_window == 48:\n",
    "            df_values = df_values0[:,\n",
    "                        [0, 1, 2, 3, 11, 5, 20, 13, 9, 14, 7, 15, 8, 6, 4, 21, 12, 17, 18, 16, 10, 19]]  # 48   LSTM\n",
    "        elif time_window == 60:\n",
    "            df_values = df_values0[:,\n",
    "                        [0, 1, 2, 3, 11, 5, 13, 20, 7, 15, 8, 14, 6, 21, 4, 9, 12, 10, 19, 18, 16, 17]]  # 60   LSTM\n",
    "    with open(result_file, 'w', encoding='UTF-8') as result_csv:\n",
    "        w = csv.writer(result_csv)\n",
    "        w.writerow(['Predicted Label', 'Label', 'Timestamp', 'NOAA AR NUM', 'HARP NUM',\n",
    "                      'TOTUSJH', 'TOTPOT', 'TOTUSJZ', 'ABSNJZH', 'SAVNCPP', 'USFLUX', 'AREA_ACR',\n",
    "                      'MEANPOT', 'R_VALUE', 'SHRGT45', 'MEANGAM', 'MEANJZH', 'MEANGBT', 'MEANGBZ',\n",
    "                      'MEANJZD', 'MEANGBH', 'MEANSHR', 'MEANALP'])\n",
    "        idx = 0\n",
    "        for i in range(len(df_values)):\n",
    "            line = df_values[i].tolist()\n",
    "            if line[0] == 'padding' or float(line[-5]) >= 3500 or float(line[-4]) >= 65536 \\\n",
    "                    or abs(float(line[-1]) - float(line[-2])) > 70:\n",
    "                continue\n",
    "            has_zero_record = False\n",
    "            # if one of the physical feature values is missing, then discard it.\n",
    "            for k in range(start_feature, start_feature + n_features):\n",
    "                if float(line[k]) == 0.0:\n",
    "                    has_zero_record = True\n",
    "                    break\n",
    "            if has_zero_record:\n",
    "                continue\n",
    "            if prob[idx] >= thresh:\n",
    "                line.insert(0, 'P')\n",
    "            else:\n",
    "                line.insert(0, 'N')\n",
    "            idx += 1\n",
    "            w.writerow(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_features_thresh(type, time_window):\n",
    "    n_features = 0\n",
    "    thresh = 0\n",
    "    if type == 'gru':\n",
    "        if time_window == 12:\n",
    "            n_features = 16\n",
    "            thresh = 0.45\n",
    "        elif time_window == 24:\n",
    "            n_features = 12\n",
    "            thresh = 0.4\n",
    "        elif time_window == 36:\n",
    "            n_features = 9\n",
    "            thresh = 0.45\n",
    "        elif time_window == 48:\n",
    "            n_features = 14\n",
    "            thresh = 0.45\n",
    "        elif time_window == 60:\n",
    "            n_features = 5\n",
    "            thresh = 0.5\n",
    "    elif type == 'lstm':\n",
    "        if time_window == 12:\n",
    "            n_features = 15\n",
    "            thresh = 0.4\n",
    "        elif time_window == 24:\n",
    "            n_features = 12\n",
    "            thresh = 0.45\n",
    "        elif time_window == 36:\n",
    "            n_features = 8\n",
    "            thresh = 0.45\n",
    "        elif time_window == 48:\n",
    "            n_features = 15\n",
    "            thresh = 0.45\n",
    "        elif time_window == 60:\n",
    "            n_features = 6\n",
    "            thresh = 0.5\n",
    "    return n_features, thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading training data...\n",
      "done loading training data...\n",
      "training the model, wait until it is finished...\n",
      "finished...\n",
      "loading testing data\n",
      "done loading testing data...\n",
      "predicting testing data...\n",
      "done predicting...\n",
      "writing prediction results into file...\n",
      "done...\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    sys.argv = ['CMEpredict.py', 'gru', 12, 0]\n",
    "    type = sys.argv[1]\n",
    "    time_window = int(sys.argv[2])\n",
    "    train_again = int(sys.argv[3])\n",
    "    train_data_file = './normalized_training_' + str(time_window) + '.csv'\n",
    "    test_data_file = './normalized_testing_' + str(time_window) + '.csv'\n",
    "    result_file = './' + type + '-' + str(time_window) + '-output.csv'\n",
    "    model_file = './' + type + '-' + str(time_window) + '-model.h5'\n",
    "    start_feature = 4\n",
    "    n_features, thresh = get_n_features_thresh(type, time_window)\n",
    "    mask_value = 0\n",
    "    series_len = 20\n",
    "    epochs = 20\n",
    "    batch_size = 256\n",
    "    nclass = 2\n",
    "    if train_again == 1:\n",
    "        # Train\n",
    "        print('loading training data...')\n",
    "        X_train, y_train, nb_train = load_data(datafile=train_data_file,\n",
    "                                               series_len=series_len,\n",
    "                                               start_feature=start_feature,\n",
    "                                               n_features=n_features,\n",
    "                                               mask_value=mask_value,\n",
    "                                               type=type,\n",
    "                                               time_window=time_window)\n",
    "        class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "        class_weight_ = {0: class_weights[0], 1: class_weights[1]}\n",
    "        print('done loading training data...')\n",
    "        if type == 'gru':\n",
    "            model = gru(n_features, series_len)\n",
    "        elif type == 'lstm':\n",
    "            model = lstm(n_features, series_len)\n",
    "        print('training the model, wait until it is finished...')\n",
    "        model.compile(loss='binary_crossentropy',\n",
    "                      optimizer='RMSprop',\n",
    "                      metrics=['accuracy'])\n",
    "        history = model.fit(X_train,\n",
    "                            y_train,\n",
    "                            epochs=epochs,\n",
    "                            batch_size=batch_size,\n",
    "                            verbose=False,\n",
    "                            shuffle=True,\n",
    "                            class_weight=class_weight_)\n",
    "        print('finished...')\n",
    "        model.save(model_file)\n",
    "    else:\n",
    "        print('loading model...')\n",
    "        model = load_model(model_file)\n",
    "        print('done loading...')\n",
    "\n",
    "    # Test\n",
    "    print('loading testing data')\n",
    "    X_test, y_test, nb_test = load_data(datafile=test_data_file,\n",
    "                                        series_len=series_len,\n",
    "                                        start_feature=start_feature,\n",
    "                                        n_features=n_features,\n",
    "                                        mask_value=mask_value,\n",
    "                                        type=type,\n",
    "                                        time_window=time_window)\n",
    "    print('done loading testing data...')\n",
    "    print('predicting testing data...')\n",
    "    prob = model.predict(X_test,\n",
    "                         batch_size=batch_size,\n",
    "                         verbose=False,\n",
    "                         steps=None)\n",
    "    print('done predicting...')\n",
    "    print('writing prediction results into file...')\n",
    "    output_result(test_data_file=test_data_file,\n",
    "                  result_file=result_file,\n",
    "                  type=type,\n",
    "                  time_window=time_window,\n",
    "                  start_feature=start_feature,\n",
    "                  n_features=n_features,\n",
    "                  thresh=thresh)\n",
    "    print('done...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
